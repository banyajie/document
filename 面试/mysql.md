#### mysql

##### mysql架构

###### 逻辑架构图

![image-20211124143304381](/Users/banyajie/Library/Application%20Support/typora-user-images/image-20211124143304381.png)

###### server层

-   连接器

    >   接收client的建立连接请求，校验user、passwd，访问权限绑定、生成连接对象
    >
    >   ```shell
    >   # 查看当前系统所有的连接
    >   show processlist;
    >   ```
    >
    >   长连接
    >
    >   ​	问题：全部使用长连接会导致mysql服务内存暴涨，导致OOM
    >
    >   ​	原因：因为 mysql 在执行过程中临时使用的内存是管理在连接对象里面，这些资源在断开连接时才会释放
    >
    >   ​	解决方案：
    >
    >   -   定期断开长连接，或者程序判断执行过一个占用内存大的查询后断开连接，后面再重新建立连接
    >   -   mysql 5.7版本后，在执行一个比较大的操作后，通过执行 mysql_reset_connection 重新初始化资源
    >
    >   短连接

-   查询缓存

    -   key （查询语句）

    -   value （查询结果）

    -   不建议使用 —— 以为命中概率太低

    -   ```shell
        select SQL_CACHE * from tableName where cond = xxx;
        ```

    -   

-   分析器

    >   词法分析
    >
    >   语法分析

-   优化器

    >   多个索引情况下选择合适的索引
    >
    >   多表查询 join时决定join顺序，提高查询效率

-   执行器

    >   根据存储引擎提供的接口获取数据

###### 存储引擎层

-   innodb
-   memory.....



##### 日志

>   -   redolog（重做日志）
>       -   工作再存储引擎层，Innodb引擎特有的。固定大小。循环写。保证db的crash-safe能力。
>       -   确保事务的持久性，防止故障发生的时间点，尚有脏页未写入磁盘，在重启mysql的时候，根据 redo log 重做，从而达到事务的持久性
>       -   物理日志（事务开始之后就开始，事务执行过程中一直写入，对应事务的脏页写入磁盘后就可以清理、覆盖了）
>   -   undolog（回滚日志）
>       -   保存事务之前数据的一个版本，可以用于回滚，同时提供多版本并发控制下的读（MVCC）
>       -   逻辑格式日志
>       -    什么时候产生：事务开始之前
>       -    什么时候释放：当事务提交之后，并不会马上清理，放在版本链里面。由purge线程清理
>   -   binlog（归档日志）：工作在server层。所有存储引擎都可以使用。追加写
>       -   Mysql  主备同步基本原理 ？
>           -   <img src="/Users/banyajie/Library/Application%20Support/typora-user-images/image-20211126110546660.png" alt="image-20211126110546660"  />
>           -   
>       -   binlog 的三种格式 ？
>           -   statement
>           -   row
>           -   mixed（statement + row）
>       -   循环复制问题 ？
>   -   errlog（错误日志）
>   -   slow query log（慢查询日志）
>   -   general log（一般查询日志）
>   -   relay log（中继日志）



##### 一条update语句的执行过程

>   -   连接器、分析器、优化器、执行
>   -   执行器调用存储引擎接口查询行数据，如果行数据在内存中直接返回，如果内存没有则从磁盘加载到内存再返回
>   -   执行操作，生成新的行数据，调用存储引擎接口写入新的行数据
>   -   引擎将行数据写入内存，同时更新到redolog中。此时redolog处于prepare状态，告知执行器执行完成，随时可以提交
>   -   执行器生成操作的binlog，并将binlog写入磁盘
>   -   执行器调用引擎事务提交，引擎把redolog状态改为commit状态。更新完成
>
>   
>
>   WAL机制（Write-Ahead Logging）
>
>   ：先写日志、再写磁盘
>
>   
>
>   问题：
>
>   -   为什么需要两阶段提交？？？
>       -   阶段1：redo log prepare
>       -   阶段2：binlog        redolog commit
>       -   保证故障恢复数据的准确性
>   -   两阶段提交过程中发生故障处理逻辑，如何保证数据的准确性的
>       -   如果redo log 里面的事务是完整的。则直接提交
>       -   如果redo log 里面只有prepare。则检查 binlog 是否完整，如果binlog完整则提交事务，不完整则回滚事务
>   -   mysql
>
>   



##### 索引

>   索引的常见模型
>
>   -   hash
>
>       -   范围查找效率低。适用与只有等值查询的场景
>
>   -   有序数组
>
>       -   更新成功太高。适用于静态存储引擎
>
>   -   查找树
>
>   -   Innodb中的索引模型
>
>       >   b+树：B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。
>       >
>       >   
>       >
>       >   主键索引
>       >
>       >   非主键索引 - 回表查询
>       >
>       >   
>       >
>       >   索引维护
>
>   -   索引最左匹配
>
>   -   覆盖索引
>
>   -   前缀索引
>
>   -   索引下推
>
>   
>
>   唯一索引和普通索引如何选择？？
>
>   -   查询过程
>       -   性能问题，无明显差别。原因：数据查询每次读取的是页数据
>
>   -   更新过程



##### change buffer

>   作用：当需要更新一个数据页时，如果数据页在内存中就直接更新，如果数据页还没有在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存再change buffer中，这样就不需要从磁盘读取数据页到内存中了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页相关的的操作。通过这种方式保证数据逻辑的正确性。
>
>   
>
>   触发merge的时机
>
>   -   查询访问到数据页
>   -   后台进程定时
>   -   数据库关闭过程
>
>   
>
>   好处
>
>   -   更新过程中减少读磁盘，提升更新的效率，而且还可以避免占用内存，提高内存利用率
>
>   
>
>   什么条件下可以使用change buffer？？
>
>   -   唯一索引不可用，原因是唯一索引每次更新都要读取数据页在内存中判断是否有冲突，所以不需要change buffer
>
>   
>
>   适用场景
>
>   -   读少写多



##### 事务

>   ACID
>
>   -   A - Atomicity 原子性
>   -   C - Consistency 一致性
>   -   I - isolation 隔离性
>   -   D - Durability 持久性
>
>   
>
>   隔离性 - 隔离级别
>
>   -   读未提交（read uncommitted）：一个事务还没提交时，它做的变更就能被别的事务看到
>   -   读提交（read committed）：一个事务提交之后，它做的变更才会被其他事务看到
>   -   可重复读（repeatable read）：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
>   -   串行化（serializable ）：写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突 的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 
>
>   
>
>   实现
>
>   read-view 视图
>
>   版本链       
>
>   MVCC（多版本并发控制）
>
>   
>
>   问题：如何避免长事务对业务的影响？？
>
>   开发端
>
>   1：set autocommit = 1。默认 autocommit = 0，该场景下每次select就会产生事务
>
>   2：确认是否有不必要的只读事务
>
>   3：设置事务持续的最大时间，通过  SET  MAX_EXECUTION_TIM 控制每个语句执行的最大时间 
>
>   数据库端
>
>   1： 监控 information_schema.Innodb_trx表，设置长事务阈值，超过就报警/或者kill；
>
>   2：在业务功能测试阶段要求输出所有的general_log，分析日志行为提前发现问题
>
>   3： 如果使用的是MySQL 5.6或者更新版本，把innodb_undo_tablespaces设置成2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便、
>
>   



##### mysql中的锁

>   -   全局锁 - 对整个数据库实例进行加锁
>       -   比如：Flush tables with read lock。当前数据库中的所有表都会是只读状态，数据的更新、删除、insert以及表的信息变更、事务的提交等都会阻塞
>       -   场景：
>       -   全库逻辑备份 - 
>   -   表级锁
>       -   表锁
>           -   lock table _read/write        unlock. table
>           -   
>       -   元数据锁（metadata lock）MDL
>           -   不需要显式使用，访问表的时候自动加锁。作用为：保证读写的正确性
>           -   在对一个表增、删、改的操作时，加 MDL 读锁
>           -   在对表结构做变更时，加 MDL 写锁
>           -   读锁之间不互斥，所以可以同时有多个线程对同一张表进行写操作
>           -   读写锁之间、写锁之间互斥，用来保证表更新的安全性
>   -   行锁
>       -   两阶段锁：在Innodb事务中，行锁是在需要的时候添加的。但是不是使用完就释放。而是必须commit提交后才释放
>       -   **问题：如何减少锁冲突提高业务并发度？**
>       -   如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放
>   -   死锁和死锁检测
>       -   当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致 这几个线程都进入无限等待的状态，称为死锁
>       -   解决方案
>       -   1：超时
>       -   2：死锁检测，回滚其中一个事务，让另外一个事务运行
>       -   问题：
>       -   **热点行更新导致的mysql性能问题？**
>       -   原因：行锁生效后，比如有1000个线程同时更新一行数据，每个被阻塞的线程都会主动发起死锁检测，判断是否是由于自己的加入导致了死锁，时间复杂度O(N)，所以如果1000个线程同时更新。操作次数为：1000*1000 百万级别的。虽然最终检测没有死锁。但是缺消耗了大量的cpu。所以cpu利用率很高，却处理不了几个事务
>       -   解决方案：
>       -   1：关闭死锁检测（不推荐）
>       -   2：中间件控制并发数
>       -   3：一行改成逻辑上的多行，减少锁冲突
>   -   间隙锁
>       -   作用：解决幻读
>       -   隔离级别：可重复读
>       -   加锁规则
>           -   
>   -   nextKey lock
>       -   
>   -   加锁规则
>       -   
>
>   

##### 视图

>   两种视图：
>
>   -   View：它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。语法：create view ... 
>   -   另一个 View 是Innodb中实现 MVCC 时用到的一致性视图，即 consistent read view 。用于支持 RC （Read Commited，读提交）、RR（Repeatable  Read， 可重复度）隔离级别的实现。没有物理结构，作用为事务执行期间定义 "我可以看到什么数据" 
>
>   
>
>   快照在MVCC里是怎么工作的？
>
>   -   InnoDB里面每个事务有一个唯一的事务ID，叫作transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的
>
>   -   而每行数据也都是有多个版本的，每次事务更新数据的时候，都会生成一个新的数据版本，并且 把transaction id赋值给这个数据版本的事务ID，记为rowtrx_id。同时，旧的数据版本要保留， 并且在新的数据版本中，能够有信息可以直接拿到它。
>
>       ![image-20211125091602213](/Users/banyajie/Library/Application%20Support/typora-user-images/image-20211125091602213.png)
>
>   -   比如图中行数据四个版本：v1、v2、v3、v4。v4为最新版本，事务ID = 25
>
>   -   undo log
>
>   -   v1、v2、v3三个版本不是真实存在的，是需要的时候根据当前版本 和 undo log计算出来的，比如需要v2版本数据，是根据v4版本执行U3、U2计算来的
>
>   
>
>   一致性视图如何实现的？
>
>   -   InnoDb 为每个事务构造了一个数组，用来保存事务启动瞬间，当前正在活跃的（启动了未提交）事务ID
>   -   低水位：数组中最新的事务ID
>   -   高水位：当前系统中已经创建过的事务ID的最大值 + 1
>   -   所以，视图数组和高水位就组成了当前事务的一致性视图
>
>   
>
>   数据版本的可见性规则
>
>   ![image-20211125092509743](/Users/banyajie/Library/Application%20Support/typora-user-images/image-20211125092509743.png)
>
>   -   基于数据的 rowtrx_id 和这个一致性视图的对比结果得到
>
>   -   绿色部分 - 可见
>
>   -   红色部分 - 不可见
>
>   -   黄色部分：
>
>       -   rowtrx_id 在数组中，标识当前数据版本是未提交的，不可见
>       -   rowtrx_id 不在数组中，已提交。可见
>
>   -   当前读规则
>
>       -   事务中update语句都是先读后写的，读的是当前的值，如果select 语句如果加锁的话。读到的也是当前数据
>
>       -   ```mysql
>            读锁（S锁、共享锁）
>            select k from t where id=1 lock in share mode;
>                    
>            写锁（排他锁）
>            select k from t where id=1 for update;
>           ```
>
>       
>
>   读提交、可重复度区别：
>
>   -   读提交隔离级别下，每一个语句执行前都会生成一个视图
>   -   可重复度隔离级别，只需要在事务开始的时候创建一个视图，之后事务里面的其他查询都用到这个视图
>
>   

##### 为什么表数据删除一半，表文件大小不变？

>   原因：逻辑删除
>
>   解决方案：重新建表



##### count(*)那么慢，如何处理？？

>   Count(*)的实现方式
>
>   -   MylSAM 引擎把一个表的总行数存在了磁盘上，每次读取直接读取直接返回，效率很高
>   -   InnoDB 引擎，执行count(*)时，需要把数据一行一行的从引擎里面读取出来，然后累积计数
>
>   
>
>   为什么InnoDB不单独存储一个表的总行数？？
>
>   由于MVCC多版本的原因，同一时间不同的事务查询行数是不确定的
>
>   
>
>   优化：
>
>   -   选择哪个索引树
>
>   
>
>   解决方案：
>
>   1.   业务单独计数（cache）—— 用缓存系统单独计数
>        1.   问题：数据不同步、数据丢失
>   2.   数据库保存计数（单独的一张表来保存其他表的总行数）
>        1.   可以通过事务解决使用cache的数据丢失的问题
>
>   
>
>   不同Count的用法已经性能分析
>
>   -   count(*)
>       -   不取值，按行累加
>   -   count(1)
>       -   InnoDB 引擎遍历整张表，但是不获取值。Server 层对于返回的每一行，放一个数字 1 进去，判断不可能为空，累加计数
>   -   count(主键ID)
>       -   InnoDB引擎遍历整张表，把每行的 ID 取出来，返回给 Server 层。Server层拿到 ID 后，判断不可能为空的，然后累加计数 
>       -   从引擎返回数据涉及到数据解析，字段值拷贝

##### order by

>   工作原理
>
>   需要排序的逻辑（数据本身是无序的）
>
>   -   全字段排序
>   -   row id 排序
>
>   不需要排序的逻辑
>
>   -   覆盖索引

##### 如何正确的处理随机查询

>   比如：
>
>   ```msyql
>    单词表
>   create table `words` (
>   	`id` int(11) NOT NULL AUTO_INCREMENT;
>   	`word` varchar(64) DEFAULT NULL,
>   ) ENGINE = InnoDB
>   ```
>
>   随机：order by rand()
>
>   
>
>   比如：select word from words order by rank() limit 3； // 随机排序取前三个

##### 索引失效

>   -   对索引字段做函数计算
>       -   比如：select count(*)  from table where month（create_time）= 7  // 查询7月份的数据行数
>       -   对索引字段做函数计算，有可能会破坏索引值的有序性，因此优化器决定放弃走树搜索功能
>   -   隐式类型转换
>       -   比如：字段 rade_id 类型是varchar
>       -   sql语句：select * from tableName wehre race_id = 11111111;         输入的参数确是整形
>       -   对于优化器来说，这条语句翻译过来  select * from tableName where CAST(race_id AS signed int) = 1111111;
>       -   所以等于对索引字段做了函数操作
>   -   隐式字符编码转换
>       -   字符集 utf8、utf8mb4

##### 为什么查询一条语句，执行特别慢

>   -   查询长时间不返回
>       -   等待MDL锁
>       -   等待flush
>       -   等待行锁
>   -   查询慢
>       -   select * from tableName where id = 1 in share mode；   // 一致性读

##### 幻读

>   什么是幻读？
>
>   ​	一个事务内前后两次查询同一个范围的时候，后一次查询看到了前一次查询未看到数据（行数据）
>
>   
>
>   -   在隔离级别（可重复读级别），普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在” 当前读 “下才会出现
>   -   幻读专指新插入的行
>
>   
>
>   如何解决幻读？
>
>   -   产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的”间隙“
>   -   间隙锁（Gap Lock）
>   -   ![image-20211125192850312](/Users/banyajie/Library/Application%20Support/typora-user-images/image-20211125192850312.png)
>   -   比如执行：select * from xxx where d = 5 for update。不光增了6个行锁，同时增加了7个间隙锁。这样就确保不会新增记录
>   -   间隙锁和行锁 合称 next-key lock
>
>   

##### 常见问题

>   