##### 消息队列



###### 为什么使用消息队列？

> - 缓冲和削峰：上游数据突发流量，下游可能扛不住或者下游没有足够的冗余机器处理请求。消息队列起到一个缓存的作用
> - 解耦和扩展性：消息队列可以作为一个接口层，解耦重要的流程。只要遵守约定就可以针对数据编程就可以增加扩展能力
> - 冗余：一对多模式
> - 健壮性：消息队列可以堆积持久化请求，即使客户端不及时处理也没关系
> - 异步通信、延时队列：



##### Kafka

###### kafka中的ISR、ASR代表什么？ISR的伸缩是什么？

> ISR：In-sync Replicas：副本同步队列
>
> OSR：outof-Sync  Replicas：不同步的副本同步队列
>
> ASR：Assigned Replicas：所有副本
>
> 伸缩：
>
> ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。



###### kafka中的broke是干什么的？

> broker 是消息的代理，Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉取指定Topic的消息，然后进行业务处理，broker在中间起到一个代理保存消息的中转站。



###### kafka中的Zookeeper起到什么作用？可以不用Zookeeper吗？

> Zookeeper 是一个分布式的协调组件，早期版本的Zookeeper用来做kafka集群的 meta 信息存储，consumer的消费状态、group组的管理以及offset的值。
>
> 新版本中逐渐弱化了zookeeper的作用。新的consumer使用了kafka内部的group coordination协议，也减少了对zookeeper的依赖，但是broker依然依赖于ZK，zookeeper 在kafka中还用来选举 controller 和 检测 broker 是否存活等等。



###### Kafka中 Follower 和 Leader 如何同步数据？

> Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。完全同步复制要求All Alive Follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，Follower异步的从Leader复制数据，数据只要被Leader写入log就被认为已经commit，这种情况下，如果leader挂掉，会丢失数据，kafka使用ISR的方式很好的均衡了确保数据不丢失以及吞吐率。
>
> Follower可以批量的从Leader复制数据，而且Leader充分利用磁盘顺序读以及send file(zero copy)机制，这样极大的提高复制性能，内部批量写磁盘，大幅减少了Follower与Leader的消息量差。



###### kafka为什么快？

> - Cache Filesystem Cache PageCache缓存
> - 顺序写 由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。
> - Zero-copy 零拷技术减少拷贝次数
> - Batching of Messages 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。
> - Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。



kafka如何优化生产者打入速度？

> - 增加线程
> - 提高 bitch.Size
> - 增加更多 producer 实例
> - 增加 partition 数
> - 设置 acks=-1 时，如果延迟增大：可以增大 num.replica.fetchers（follower 同步数据的线程数）来调解；
> - 跨数据中心的传输：增加 socket 缓冲区设置以及 OS tcp 缓冲区设置



###### Kafka Producer 打数据？ack设置0/1、-1的时候代表啥？设置-1的时候，什么情况下，leader会认为一条消息commit？

> - 1（默认） 数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。在这种情况下，如果leader宕机了，则会丢失数据。
> - 0 生产者将数据发送出去就不管了，不去等待任何返回。这种情况下数据传输效率最高，但是数据可靠性确是最低的。
> - -1 producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。当ISR中所有Replica都向Leader发送ACK时，leader才commit，这时候producer才能认为一个请求中的消息都commit了。



###### Kafka unclean 代表什么？会对 spark streaming 有什么影响？

> unclean.leader.election.enable 为true的话，意味着非ISR集合的broker 也可以参与选举，这样有可能就会丢数据，spark streaming在消费过程中拿到的 end offset 会突然变小，导致 spark streaming job挂掉。如果unclean.leader.election.enable参数设置为true，就有可能发生数据丢失和数据不一致的情况，Kafka的可靠性就会降低；而如果unclean.leader.election.enable参数设置为false，Kafka的可用性就会降低。



###### 如果Leader crash，ISR为空怎么办？

> kafka在Broker端提供了一个配置参数：unclean.leader.election,这个参数有两个值：
>
> true（默认）：允许不同步副本成为leader，由于不同步副本的消息较为滞后，此时成为leader，可能会出现消息不一致的情况。
>
> false：不允许不同步副本成为leader，此时如果发生ISR列表为空，会一直等待旧leader恢复，降低了可用性。



###### kafka中的 Consumer Group 是什么概念？

> 同样是逻辑上的概念，是Kafka实现单播和广播两种消息模型的手段。同一个topic的数据，会广播给不同的group；同一个group中的worker，只有一个worker能拿到这个数据。换句话说，对于同一个topic，每个group都可以拿到同样的所有数据，但是数据进入group后只能被其中的一个worker消费。group内的worker可以使用多线程或多进程来实现，也可以将进程分散在多台机器上，worker的数量通常不超过partition的数量，且二者最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费（同一group内）。



###### kafka中消息是否丢失 或者 重复消费？

> - 消息发送
>   - Kafka消息发送有两种方式：同步（sync）和异步（async），默认是同步方式，可通过producer.type属性进行配置。Kafka通过配置request.required.acks属性来确认消息的生产
>   - 0---表示不进行消息接收是否成功的确认
>   - 1---表示当Leader接收成功时确认
>   - -1---表示Leader和Follower都接收成功时确认
>   - 
>   - 所以有两种情况可能导致消息丢失？
>     - acks=0，不和Kafka集群进行消息接收确认，则当网络异常、缓冲区满了等情况时，消息可能丢失
>     - acks=1、同步模式下，只有Leader确认接收成功后但挂掉了，副本没有同步，数据可能丢失；
>   - 解决办法
>     - 针对消息丢失：
>     - 同步模式下，确认机制设置为-1，即让消息写入Leader和Follower之后再确认消息发送成功；
>     - 异步模式下，为防止缓冲区满，可以在配置文件设置不限制阻塞超时时间，当缓冲区满时让生产者一直处于阻塞状态；
>     - 
> - 消息接收
>   - Kafka消息消费有两个consumer接口，Low-level API和High-level API：
>   - Low-level API：消费者自己维护offset等值，可以实现对Kafka的完全控制；
>   - High-level API：封装了对parition和offset的管理，使用简单；
>   - 如果使用高级接口High-level API，可能存在一个问题就是当消息消费者从集群中把消息取出来、并提交了新的消息offset值后，还没来得及消费就挂掉了，那么下次再消费时之前没消费成功的消息就“诡异”的消失了；
>     - 将消息的唯一标识保存到外部介质中，每次消费时判断是否处理过即可。



###### 为什么kafka不支持读写分离？

> 在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。
>
> Kafka 并不支持主写从读，因为主写从读有 2 个很明 显的缺点:
>
> - 数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。
> - 延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用



###### kafka中怎么体现消息的顺序性？

> kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。
>
> 整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.



###### Kafka 如何实现延时队列？

> Kafka并没有使用JDK自带的Timer或者DelayQueue来实现延迟的功能，而是基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）。JDK的Timer和DelayQueue插入和删除操作的平均时间复杂度为O(nlog(n))，并不能满足Kafka的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为O(1)。时间轮的应用并非Kafka独有，其应用场景还有很多，在Netty、Akka、Quartz、Zookeeper等组件中都存在时间轮的踪影。
>
> 底层使用数组实现，数组中的每个元素可以存放一个TimerTaskList对象。TimerTaskList是一个环形双向链表，在其中的链表项TimerTaskEntry中封装了真正的定时任务TimerTask.
>
> Kafka中到底是怎么推进时间的呢？Kafka中的定时器借助了JDK中的DelayQueue来协助推进时间轮。具体做法是对于每个使用到的TimerTaskList都会加入到DelayQueue中。Kafka中的TimingWheel专门用来执行插入和删除TimerTaskEntry的操作，而DelayQueue专门负责时间推进的任务。再试想一下，DelayQueue中的第一个超时任务列表的expiration为200ms，第二个超时任务为840ms，这里获取DelayQueue的队头只需要O(1)的时间复杂度。如果采用每秒定时推进，那么获取到第一个超时的任务列表时执行的200次推进中有199次属于“空推进”，而获取到第二个超时任务时有需要执行639次“空推进”，这样会无故空耗机器的性能资源，这里采用DelayQueue来辅助以少量空间换时间，从而做到了“精准推进”。Kafka中的定时器真可谓是“知人善用”，用TimingWheel做最擅长的任务添加和删除操作，而用DelayQueue做最擅长的时间推进工作，相辅相成。



###### Kafka 中事务是怎么实现的？

> 幂等：简单地说就是对接口的多次调用所产生的结果和调用一次是一致的。生产者在进行重试的时候有可能会重复写入消息，而使用Kafka的幂等性功能之后就可以避免这种情况。开启幂等性功能的方式很简单，只需要显式地将生产者客户端参数enable.idempotence设置为true即可
>
> 实现原理
>
> - producer id（以下简称PID）和序列号（sequence number）这两个概念。每个新的生产者实例在初始化的时候都会被分配一个PID，这个PID对用户而言是完全透明的。
> - 对于每个PID，消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增。生产者每发送一条消息就会将对应的序列号的值加1
> - broker端会在内存中为每一对维护一个序列号。对于收到的每一条消息，只有当它的序列号的值（SN_new）比broker端中维护的对应的序列号的值（SN_old）大1（即SN_new = SN_old + 1）时，broker才会接收它
> - 如果SN_new< SN_old + 1，那么说明消息被重复写入，broker可以直接将其丢弃。如果SN_new> SN_old + 1，那么说明中间有数据尚未写入，出现了乱序，暗示可能有消息丢失，这个异常是一个严重的异常
> - 引入序列号来实现幂等也只是针对每一对而言的，也就是说，Kafka的幂等只能保证单个生产者会话（session）中单分区的幂等。幂等性不能跨多个分区运作，而事务可以弥补这个缺陷。
>
> 事务：事务可以保证对多个分区写入操作的原子性。操作的原子性是指多个操作要么全部成功，要么全部失败，不存在部分成功、部分失败的可能。
>
> - transactionalId （事务ID）
> - transactionalId与PID一一对应，两者之间所不同的是transactionalId由用户显式设置，而PID是由Kafka内部分配的
> - 为了保证新的生产者启动后具有相同transactionalId的旧生产者能够立即失效，每个生产者通过transactionalId获取PID的同时，还会获取一个单调递增的producer epoch。如果使用同一个transactionalId开启两个生产者，那么前一个开启的生产者会报错。
> - 



###### kafka中哪些地方有选举？用了什么选举策略？

> - 控制器（broker）选主
>
>   - 集群中第一个启动的broker会通过在zookeeper中创建临时节点/controller来让自己成为控制器，其他broker启动时也会在zookeeper中创建临时节点，但是发现节点已经存在，所以它们会收到一个异常，意识到控制器已经存在，那么就会在zookeeper中创建watch对象，便于它们收到控制器变更的通知
>   - 那么如果控制器由于网络原因与zookeeper断开连接或者异常退出，那么其他broker通过watch收到控制器变更的通知，就会去尝试创建临时节点/controller，如果有一个broker创建成功，那么其他broker就会收到创建异常通知，也就意味着集群中已经有了控制器，其他broker只需创建watch对象即可。
>   - 如果集群中有一个broker发生异常退出了，那么控制器就会检查这个broker是否有分区的副本leader，如果有那么这个分区就需要一个新的leader，此时控制器就会去遍历其他副本，决定哪一个成为新的leader，同时更新分区的ISR集合。
>   - 如果有一个broker加入集群中，那么控制器就会通过Broker ID去判断新加入的broker中是否含有现有分区的副本，如果有，就会从分区副本中去同步数据。
>   - 集群中每选举一次控制器，就会通过zookeeper创建一个controller epoch，每一个选举都会创建一个更大，包含最新信息的epoch，如果有broker收到比这个epoch旧的数据，就会忽略它们，kafka也通过这个epoch来防止集群产生“脑裂”。
>     
>
> - 分区多副本选主
>
>   - 在kafka的集群中，会存在着多个主题topic，在每一个topic中，又被划分为多个partition，为了防止数据不丢失，每一个partition又有多个副本，在整个集群中，总共有三种副本角色
>     - 首领副本（leader）：也就是leader主副本，每个分区都有一个首领副本，为了保证数据一致性，所有的生产者与消费者的请求都会经过该副本来处理。
>     - 跟随者副本（follower）：除了首领副本外的其他所有副本都是跟随者副本，跟随者副本不处理来自客户端的任何请求，只负责从首领副本同步数据，保证与首领保持一致。如果首领副本发生崩溃，就会从这其中选举出一个leader。
>     - 首选首领副本：创建分区时指定的首选首领。如果不指定，则为分区的第一个副本
>   - 选举过程
>     - 从Zookeeper中读取当前分区的所有ISR(in-sync replicas)集合
>     - 调用配置的分区选择算法选择分区的leader
>
> - 消费组选主
>
>   - 在kafka的消费端，会有一个消费者协调器以及消费组，组协调器GroupCoordinator需要为消费组内的消费者选举出一个消费组的leader，那么如何选举的呢？
>
>     如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader，如果某一个时刻leader消费者由于某些原因退出了消费组，那么就会重新选举leader，如何选举？
>
>     ```java
>     
>     private val members = new mutable.HashMap[String, MemberMetadata]
>     leaderId = members.keys.headOption
>     ```
>
>     随机选举
>
> 



###### Kafka 分区数量是否可以增加或者减少？

> 



###### Kafka中的HW、LEO、LSO、LW分别代表什么？

> - HW:High Watermark 高水位，取一个partition对应的ISR中最小的LEO作为HW，consumer最多只能消费到HW所在的位置上一条信息。
> - LEO:LogEndOffset 当前日志文件中下一条待写信息的offset
> - HW/LEO这两个都是指最后一条的下一条的位置而不是指最后一条的位置。
> - LSO:Last Stable Offset 对未完成的事务而言，LSO 的值等于事务中第一条消息的位置(firstUnstableOffset)，对已完成的事务而言，它的值同 HW 相同
> - LW:Low Watermark 低水位, 代表 AR 集合中最小的 logStartOffset 值



Kafka 生产者客户端中使用了几个线程处理？分别是什么？

> - 主线程
>   - 负责创建消息，然后通过分区器、序列化器、拦截器作用之后缓存到累加器RecordAccumulator中。
> - Sender线程
>   - Sender线程负责将RecordAccumulator中消息发送到kafka中.



